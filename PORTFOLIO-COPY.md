# Esraa Elnagdi — Portfolio Copy

All text content from the live portfolio at https://esraa-elnagdi-portfolio.netlify.app

---

## NAVIGATION

- E.E. | The Lab
- Origin Story
- Experiments
- Side Lab
- Contact

---

## HERO

**Name:** Esraa Elnagdi

**Headline:** Biochemist turned product builder.

**Bio:** 10 years translating the gap between what teams build and why customers care. I've launched platforms from 0 to 8,000+ users, shipped learning programs with 70% completion rates, and driven 19% engagement lifts through experimentation. Across EdTech, PropTech, FinTech, and consumer apps — same instinct every time: start with the customer, understand the system, build something better.

**Buttons:** View Work | Get in Touch

**Metrics:**
- 10 yrs — in product & GTM
- 750+ — companies on platforms I've launched
- 98% — reduction in creation time
- 19% — engagement lift from my last experiment

---

## Origin Story

I've always been a translator.

As a teenager and newcomer to Canada, I translated for my mom at doctor's appointments, turning medical jargon into decisions we could act on. That instinct never left.

I studied Biochemistry at the University of Toronto. I loved it not for the career path, but for the way of thinking. Form hypotheses. Test them. Follow the evidence. Think in systems. I led research and co-authored a published paper, translating questions into experiments and experiments into findings.

My first job in tech was answering phones at a call centre at Propel Holdings. I talked to customers all day, hearing their bugs, feature requests, and what they wished the product could do. I got curious about the online application flow and customer dashboard I was helping them navigate every day. I understood the customer web experience inside out, which earned me a move to Business Analyst, then Scrum Master leading a team of 8 engineers.

That's been my pattern ever since: start with the customer, understand the system, then translate complexity into something people can actually use.

At Altus Group, I was the Product Owner on a commercial real estate data platform, and with no PMM function, I built that too. I interviewed customers, developed segmented positioning for three buyer personas, created 30+ help articles, and trained Sales on persona-specific selling. The platform grew from 0 to 750+ companies and 8,000+ users.

At Yelp, I learned the power of experimentation, partnering with Data Science to build predictive models and running A/B tests that drove a 19% engagement lift.

At MasterClass, I brought it all together: leading cross-functional teams of 10+, shipping enterprise learning programs with completion rates 4x the existing product, building an internal tool that cut content curation by 98%, developing GTM strategy, and beating revenue targets by 10% YoY.

I've translated across languages, industries, and audiences. From Arabic to English, from biochemistry labs to engineering sprints, from technical complexity to business outcomes. I'm a first-generation Canadian, Egyptian by origin, I lead with active listening and empathy. I thrive in the space between chaos and clarity, building the systems that turn one into the other.

### Lab Profile — The Planner / Translator
PRIOS Assessment, 2025

**Traits:**
- Systematic: 92%
- Driven: 89%
- Logical: 82%
- Visionary: 75%
- Empathetic: 60%

**Languages:** English, Arabic

**Trained In:**
- Biochemistry (HBSc, UofT)
- Advanced Product Management (Product Faculty)
- Pragmatic Institute, PMC Level I

**Product & Analytics:**
Jira, Figma, Miro, Amplitude, Google Analytics, Looker

**AI & Automation:**
Claude Code, Lovable, n8n

**Companies I've Worked With:**
MasterClass, Yelp, Altus Group, Propel Holdings

---

## Experiments

---

### EXP-001 | MasterClass
**Can a consumer brand sell structured learning to enterprises?**

Product Manager
Tags: PM, GTM, CROSS-FUNCTIONAL, 0→1

**Hero Metrics:**
- 47% — NPS improvement over existing formats (44.53 vs. 30.27)
- $5.5M — Enterprise pipeline influenced
- 44% — Sales call adoption rate
- +51% — Weekly Active Admin lift

**Hypothesis:** Enterprise buyers would adopt guided learning if positioned around career outcomes — not celebrity appeal.

**The Problem:**
MasterClass at Work had a rich content library — celebrity instructors, beautifully produced videos — but enterprise L&D admins were overwhelmed. They didn't know what content to assign, to whom, or how to structure it into a learning program. The CS team was spending hours per client manually curating content and mapping it to customer goals, and that model didn't scale. The result: deals stalled, customers churned, and the number-one reason cited by Sales was that admins didn't know how to use the platform.

**Method:**

**Discovery:** I synthesized feedback from CS, sales call recordings, admin survey data, and a UXR study I designed with 10 L&D professionals. The research revealed three core sub-problems: admins didn't know what content to assign, they spent too much time piecing together resources, and they lacked awareness of existing admin tools.

**Build approach:** I evaluated four technical approaches in a Product Review with engineering leadership. We could build Programs as (a) an enhanced viewing experience, (b) a landing page with curated content collections, (c) an entirely new content type, or (d) leverage existing infrastructure. Each had different effort levels (2–26 weeks of engineering) and tradeoffs. I recommended the landing page approach — it let us ship in 8 weeks while preserving existing analytics and content infrastructure. I framed the decision around a principle: time-box investment until we have conviction of value.

**Scoping:** I defined clear P0/P1/P2 prioritization. P0 included the admin program page with resources, ability to share programs, learner experience across web/iOS/Android, progress monitoring, and NPS surveys. I deliberately descoped features like scheduled drip emails and badging as P2 — even though stakeholders wanted them — because they would have added 4+ weeks and we needed to validate the core concept first.

**Execution:** I orchestrated a cross-functional pod of 15+ people spanning Product, Engineering (FE/BE/iOS/Android), Content/Learning Design, Creative, Marketing, Sales Enablement, and Customer Success. I ran weekly pod meetings to coordinate dependencies and track blockers. When the CS team and Content team disagreed on how facilitator resources should work (configurable per client vs. single format), I reframed the decision around the user need: what does the admin need to deploy successfully? We shipped admin-facing defaults with CS tailoring per client relationship. Two key team members went on leave mid-project — I proactively set up coverage and handoff plans so launches proceeded without escalation.

**Phased GTM:** I designed a three-phase launch strategy to work around the constraint that summer is historically dead for L&D buyers. Phase 1: pre-launch at the ATD industry conference with a Figma prototype and demo environment, generating early market validation. Phase 2: staggered soft launch of three programs across web, iOS, and Android, timed to engineering readiness. Phase 3: hard launch with prospect email campaigns and admin newsletter inclusion, timed to the fall buying season. This gave us 6–8 weeks of live data and customer feedback before the big push.

**Positioning & enablement:** Developed outcome-focused positioning around career development — not celebrity appeal — to resonate with L&D buyers evaluating ROI. Ran an unmoderated UXR survey with 10 participants comparing three merchandising variants (instructor-forward, outcome-forward, and information-dense) to inform in-product placement: light merchandising on mobile, aggressive on web with homepage, skill page, and dedicated Programs page placement. For the ATD conference pre-launch, created a sales brief, talk track, Figma prototype with a custom demo environment, and one-pager — giving the sales team a way to demo the concept before the product existed. Ahead of soft launch, built enablement slides, SDR outbound copy, and messaging templates, and ran a sales training kickoff so the team was actively selling before go-live. For hard launch, planned prospect email campaigns and inclusion in the admin newsletter. Post-launch, evolved positioning from "structured learning paths" to "measurable learning outcomes" based on customer feedback showing buyers cared more about completion and skill application than program structure.

**Feedback engine:** I built a four-layer measurement system to generate a build/hold/pivot recommendation within 90 days. Layer 1: quantitative product data (completion rates, NPS, Weekly Active Admins). Layer 2: passive sales call tracking via Gong smart trackers that auto-flagged Programs mentions — a creative approach that avoided relying on self-reporting. Layer 3: structured qualitative feedback sheet where CS and Sales logged client reactions, categorized by type (Product Experience, Content, Branding). Layer 4: effectiveness surveys triggered at the module level. I synthesized all four layers into Product Reviews at 30 days and 90 days, presenting an executive summary, quantitative comparison against other content types, qualitative highlights with client quotes, and a clear recommendation.

**Results:**
- 47% — NPS improvement (44.53 vs. 30.27 for other enterprise learning formats)
- 50–60% — Module completion rates (vs. ~14% for prior formats)
- $5.5M — Enterprise pipeline influenced
- 44% — Sales calls mentioning Programs within 90 days
- +51% — Weekly Active Admin lift
- 60% — Of engaged admins had been inactive in prior months, indicating Programs drove re-engagement

**Key Finding:**
The celebrity brand got meetings. Outcome-focused positioning closed deals. Admins didn't need more content — they needed structured, deployable solutions that made them look good internally. The biggest unlock wasn't the product itself but the positioning shift: framing Programs around measurable career outcomes rather than instructor names.

---

### EXP-002 | MasterClass
**Can you eliminate engineering dependency from a content workflow?**

Product Manager
Tags: PM, TPM, INTERNAL TOOLING, OPS

**Hero Metric:** 98% reduction in creation time

**Hypothesis:** A self-service tool would unlock CSM autonomy and drive higher engagement than manual processes.

**The Problem:**
CSMs were curating custom learning playlists for enterprise clients. Each playlist took 4–5 hours — hunting through spreadsheets for video IDs across multiple systems, then submitting to Engineering to run a script. Every creation and edit required Eng support.

CSMs were afraid of the existing admin tool — no guardrails, no validation, real risk of breaking things. A previous attempt to solve this with documentation failed: 1 out of 6 CSMs adopted it. The problem was the tool, not the training.

**Method:**

**Options analysis:** Evaluated three approaches at a formal Product Review. Enhancing the data submission process still required Eng. Enhancing the admin tool was "an uphill fight" with worse UX. Building a dedicated creator in the admin platform was the clear winner — and architecturally close to eventually being customer-facing.

**Guardrail-driven design:** The core UX insight was that CSMs were afraid of breaking things. Every design decision addressed this: a two-phase publishing workflow (publish to internal demo account first, then to client), validation modals showing exactly what's missing, double-confirm on edits to published playlists, and a CSM-scoped role that hid dangerous permissions.

**Delivery under constraints:** One of five concurrent initiatives. Shared FE resources with a partnership that had a non-negotiable deadline. Accepted the constraint, adjusted timeline, and overlapped UAT with test engineering when FE fell behind — rather than cutting scope.

**Chaos testing:** Ran deliberate break-the-tool sessions before launch. Caught 14 bugs including critical ones (publishing with no lessons, instructors not updating on removal). All critical bugs resolved before launch.

**Brand quality:** Authored a Creative Brief for 40 brand-approved assets across 10 skill categories — not in my job description, but without it CSMs would have shipped off-brand thumbnails.

**Enablement:** Wrote a comprehensive guide with screen recordings, content rights restrictions, and the two-phase publishing workflow. Set up feedback channels, peer-review process, and ongoing CSM syncs.

**Results:**
- 98% — Creation time reduction (4–5 hours → under 5 minutes)
- 190+ — Playlists created in the first 90 days post-launch
- #1 — Highest 30D/90D engagement of all enterprise content types
- Top NPS — Higher than both existing playlists and Programs
- 50%+ — Consumers were admin-assigned (intentional learning)
- 14 — Pre-launch bugs caught, all critical issues resolved
- CSM team self-sufficient from day one — zero training friction

**Key Finding:**
The best internal tools eliminate fear, not just friction. Two-phase publishing, validation modals, scoped permissions, and peer review all addressed one root issue: CSMs were afraid of breaking things. The failed documentation attempt proved the problem was never training — it was the tool. Once fear was removed, adoption was instant.

---

### EXP-003 | Altus Group
**Can segmented positioning unlock a fragmented market?**

Senior Product Owner (de facto PMM)
Tags: PMM, GTM, POSITIONING, SALES ENABLEMENT

**Hero Metric:** 750+ companies adopted

**Hypothesis:** Speaking differently to each buyer segment would drive adoption against entrenched competitors.

**The Problem:**
Altus Group was building a unified CRE data platform to replace two aging, siloed legacy systems. The market was dominated by entrenched players. The platform needed to serve fundamentally different buyers — valuators, brokers, developers, and home builders — each with different workflows and definitions of "valuable."

There was no product marketing function. The gap between what we built and what the field could articulate grew with every release.

**Method:**

**Customer research:** Conducted 15 interviews across four buyer personas using an unbiased framework I designed. One session uncovered seven distinct pain points — including that users relied on search 90% of the time and the map only 10%, directly reshaping engineering priorities.

**Usage analysis:** Analyzed 12 months of legacy platform data (17,000+ page views) to build a prioritization map grounded in actual behavior, not stakeholder opinions.

**Four positioning strategies:** Developed distinct value propositions for valuators (historical data depth), CRE professionals (market intelligence), developers (economic forecasting), and home builders (market trends). Refined based on Sales feedback — they flagged that "comprehensive" mattered less to builders than "forecasting."

**GTM engine:** Operated as de facto PMM, building three systems. First, a product marketing brief template for every release — Marketing could draft communications without deep product knowledge. Second, one-page competitive battlecards in "If they say / You say" format, objection handlers, and persona-specific demo scripts. Third, 30+ help articles and 10 tutorial videos reducing support burden and improving time-to-value.

**Release sequencing:** Organized releases around use-case completion, not feature shipping. Each release fully served a user segment so Sales could migrate clients with confidence. Built company-level adoption dashboards and flagged at-risk accounts to CS with specific context.

**Quality:** Personally QA'd calculated metrics (vacancy rates, rental rates, occupancy costs) against legacy definitions. One miscalculated number would have destroyed trust with professional users.

**Results:**
- 750+ — Companies on platform (0 → 750+ in 3 years)
- 8,000+ — Active users
- +5% — ARR contribution
- +15% — Feature adoption through education and enablement
- Battlecard usage went from near-zero to standard practice across the Sales team — the "If they say / You say" format matched how reps actually sold

**Key Finding:**
One message for all buyers means no message resonates deeply with anyone. Segmented positioning worked because it was paired with practical enablement — one-page battlecards Sales actually used, objection handlers grounded in real conversations, and content that helped customers get to value faster. Operating as the bridge between Product, Sales, Marketing, and CS created compounding growth.

---

### EXP-004 | Yelp
**What actually drives long-term business owner engagement?**

Product Manager
Tags: PM, GROWTH, EXPERIMENTATION, DATA SCIENCE

**Hero Metric:** 19% engagement lift

**Hypothesis:** Engagement behaviors — not profile completion — predict business owner success.

**The Problem:**
Yelp for Business had flat WAU growth. The team assumed onboarding was the bottleneck — get business owners to complete setup, and engagement follows. Meanwhile, a recently launched recommendations feature was underperforming despite working well technically.

**Method:**

**Predictive modeling:** Partnered with Data Science to build models identifying success predictors for business owners. Used Poisson regression with confounding variable controls. The result contradicted the team's core assumption: responding to reviews created a 2.76x pageview multiplier and responding to messages created 2.28x — but setup completion was NOT a significant predictor of long-term engagement.

**Onboarding A/B testing:** Despite setup not being the primary driver, the flow still had 40% drop-off. Tested three variants across 5,000 users each. The winner: reordering steps so users saw value before being asked to pay. Combined best elements from multiple variants and iterated across all platforms to achieve +10% setup rate improvement.

**Messaging experimentation:** The recommendations feature was underperforming due to positioning, not product quality. Tested three messaging approaches with 10,000 users each. Functional messaging ("You have 3 actions"): low engagement. Value messaging ("Respond faster to attract customers"): moderate. ROI messaging ("Businesses that do this get 20% more messages"): 4x the action rate of functional. Repositioned the entire feature around data-driven business improvement.

**Opportunity sizing:** Identified a large pool of dormant business owners visiting the consumer site but not engaging with their business profiles. Launched a feature targeting them, generating statistically significant increases in engagement. Built self-service dashboards and a 1-year roadmap targeting 10% WAU growth.

**Results:**
- +19% — Recommendations engagement (exceeded target)
- +10% — Onboarding completion across all platforms
- +10% — WAU growth (met annual target)
- +15% — Homepage engagement across combined initiatives
- +49–51% — Relative CTR improvement on mobile
- 4x — Action rate — ROI messaging vs. functional
- 2.76x — Pageview multiplier for review responders

**Key Finding:**
The predictive model told a completely different story than our assumptions. Setup didn't predict success — engagement behaviors did. That single insight shifted the entire team's strategy. And the messaging test proved positioning matters as much as product: same feature, better framing, 4x the results.

---

## Side Lab

**AI Skills:**
- Competitive Analysis Skill — Automates end-to-end competitive analysis for 2–5 companies across 13 dimensions. Researches positioning, pricing, features, and customer proof, then generates a 16-slide deck. One command replaces hours of manual research. (github.com/elnagdie/competitive-analysis)

**Projects:**
- YouTube Transcriber — Paste a URL, get the transcript. Supports videos, playlists, and channels. (github.com/elnagdie/youtube-transcriber)
- Trivia Engine — Reusable trivia game engine with themed editions. (github.com/elnagdie/trivia-engine)
- Duck Hunt — Browser game. My first AI-assisted build with Claude Code. (github.com/elnagdie/duck-hunt)

---

## Let's Build Something

- Email: esraa.y.elnagdi@gmail.com
- LinkedIn: linkedin.com/in/esraa-elnagdi
- GitHub: github.com/elnagdie

---

(c) 2026 Esraa Elnagdi
Built with curiosity and Claude Code.
